# To review configuration:
# docker compose -f compose.yaml -f model-runner.yaml config
# https://docs.docker.com/compose/how-tos/multiple-compose-files/merge/

# Use !reset to remove values:
# https://docs.docker.com/reference/compose-file/merge/

services:
  agent:
    secrets: !reset []
    environment:
      # Base URL for the model (OpenAI API-compatible endpoint)
      - MODEL_RUNNER_URL=http://model-runner.docker.internal:12434/engines/llama.cpp/v1
      # Model to use
      - MODEL_RUNNER_MODEL=ai/gemma3:4B-Q4_0
    extra_hosts:
      # Used to make the API endpoint available in the container
      # https://docs.docker.com/ai/model-runner/#what-api-endpoints-are-available
      - "model-runner.docker.internal:host-gateway"
    models:
      - gemma3

models:
  gemma3:
    # Pre-pull the model when starting Docker Model Runner
    model: ai/gemma3:4B-Q4_0
    context_size: 10000 # 3.5 GB VRAM

secrets: !reset []
